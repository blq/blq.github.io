<!DOCTYPE html>
<html lang="en">
<head>
	<title>three.js ar map</title>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
	<link rel="stylesheet" href="main.css">

	<script src="https://api.mapbox.com/mapbox-gl-js/v1.9.0/mapbox-gl.js"></script>
	<link href="https://api.mapbox.com/mapbox-gl-js/v1.9.0/mapbox-gl.css" rel="stylesheet" />

	<style>
		#container {
			width: 640px;
			height: 480px;
		}

		#map {
			width: 256px;
			height: 256px;
		}
	</style>
</head>
<body>
	<div id="info">
		<a href="https://threejs.org" target="_blank" rel="noopener">three.js</a> ar - hit test<br/>Enable chrome://flags/#webxr-ar-module<br/>Enable chrome://flags/#webxr-hit-test<br/>(Chrome Android 81+)
	</div>

	<div id="container"></div>

	<!-- <video id="video" autoplay style="display:none"></video> -->

	<script type="module">
		// Import three
		import * as THREE from 'https://unpkg.com/three/build/three.module.js';
		// Import the default ARButton
		import { ARButton } from 'https://unpkg.com/three/examples/jsm/webxr/ARButton.js';

		var camera, scene, renderer;
		var controller;

		var reticle;

		var hitTestSource = null;
		var hitTestSourceRequested = false;

		var _mesh = null;
		var _mapVideo = null;
		var video = null;
		var vidTexture = null;

		// init();
		// animate();

		createMap();

		function init() {

			renderer = new THREE.WebGLRenderer( { antialias: true, alpha: true, preserveDrawingBuffer: true } );
			renderer.setPixelRatio( window.devicePixelRatio );
			renderer.setSize( window.innerWidth, window.innerHeight );
			renderer.xr.enabled = true;

			document.getElementById('container').appendChild( renderer.domElement );

			document.body.appendChild( ARButton.createButton( renderer, { requiredFeatures: [ 'hit-test' ] } ) );

			scene = new THREE.Scene();

			camera = new THREE.PerspectiveCamera( 70, window.innerWidth / window.innerHeight, 0.01, 20 );

			controller = renderer.xr.getController( 0 );
			controller.addEventListener( 'select', onSelect );
			scene.add( controller );

			var light = new THREE.HemisphereLight( 0xffffff, 0xbbbbff, 1 );
			light.position.set( 0.5, 1, 0.25 );
			scene.add( light );

			var geometry = new THREE.CylinderBufferGeometry( 0.25, 0.25, 0.2, 32 ).translate( 0, 0.1, 0 );

			function onSelect() {
				if ( reticle.visible ) {
					var material = new THREE.MeshPhongMaterial( { color: 0xffffff * Math.random() } );

					try {
						if (vidTexture) {
							material.map = vidTexture;
						} else {
							const tmap = new THREE.TextureLoader().load('grass.png');
							material.map = tmap;
						}
					} catch (ex) {

					}

					var mesh = new THREE.Mesh( geometry, material );
					mesh.position.setFromMatrixPosition( reticle.matrix );
					mesh.scale.y = Math.random() * 0.1 + 0.4;
					_mesh = mesh;

					scene.add( mesh );
				}
			}

			reticle = new THREE.Mesh(
				new THREE.RingBufferGeometry( 0.15, 0.2, 32 ).rotateX( - Math.PI / 2 ),
				new THREE.MeshBasicMaterial()
			);
			reticle.matrixAutoUpdate = false;
			reticle.visible = false;
			scene.add( reticle );

			window.addEventListener( 'resize', onWindowResize, false );
		}

		function onWindowResize() {
			camera.aspect = window.innerWidth / window.innerHeight;
			camera.updateProjectionMatrix();

			renderer.setSize( window.innerWidth, window.innerHeight );
		}

		//
		function animate() {
			renderer.setAnimationLoop( render );
		}

		function render( timestamp, frame ) {
			if ( frame ) {
				var referenceSpace = renderer.xr.getReferenceSpace();
				var session = renderer.xr.getSession();

				if (!hitTestSourceRequested) {
					session.requestReferenceSpace( 'viewer' ).then( function ( referenceSpace ) {
						session.requestHitTestSource( { space: referenceSpace } ).then( function ( source ) {
							hitTestSource = source;
						});
					});

					session.addEventListener( 'end', function () {
						hitTestSourceRequested = false;
						hitTestSource = null;
					});

					hitTestSourceRequested = true;
				}

				if ( hitTestSource ) {
					var hitTestResults = frame.getHitTestResults( hitTestSource );
					if ( hitTestResults.length ) {
						var hit = hitTestResults[ 0 ];

						reticle.visible = true;
						reticle.matrix.fromArray( hit.getPose( referenceSpace ).transform.matrix );
					} else {
						reticle.visible = false;
					}
				}
			}

			renderer.render( scene, camera );
		}

		function drawCanvas(canvas, img) {
			canvas.width = getComputedStyle(canvas).width.split('px')[0];
			canvas.height = getComputedStyle(canvas).height.split('px')[0];
			let ratio  = Math.min(canvas.width / img.width, canvas.height / img.height);
			let x = (canvas.width - img.width * ratio) / 2;
			let y = (canvas.height - img.height * ratio) / 2;
			canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);
			canvas.getContext('2d').drawImage(img, 0, 0, img.width, img.height,	x, y, img.width * ratio, img.height * ratio);
		}

		function createMap() {
			// F-K in XR mode cam can't be used.. And do any phone allow you to use 2nd camera (both) at same time?!
			video = document.createElement('video');
			// video = document.getElementById( 'video' );
			video.autoplay = true;
			video.loop = true;
			video.muted = true;
			// video.width = video.height = 512;

			var canvas = document.createElement('canvas');
			//canvas.width = 640;
			//canvas.height = 480;

			var imageCapture = null;

			if (false && navigator.mediaDevices && navigator.mediaDevices.getUserMedia ) {

				var constraints = { video: { /*width: 1280, height: 720,*/ facingMode: 'environment' } };

				navigator.mediaDevices.getUserMedia( constraints ).then( function ( stream ) {

					// apply the stream to the video element used in the texture

					// video.srcObject = stream;
					// video.play();

					const track = stream.getVideoTracks()[0];
					imageCapture = new ImageCapture(track);

					function spin() {
						imageCapture.grabFrame().then(
						// imageCapture.takePhoto().then(
							(imageBitmap) => {
								// drawCanvas(canvas, imageBitmap);
								canvas.width = imageBitmap.width;
								canvas.height = imageBitmap.height;
								canvas.getContext('2d').drawImage(imageBitmap, 0, 0);

								if (!vidTexture) {
									// vidTexture = new THREE.CanvasTexture(canvas);
									vidTexture = new THREE.CanvasTexture(renderer.domElement);
								} else {
									vidTexture.needsUpdate = true;
								}

								setTimeout(() => {
									requestAnimationFrame(spin);
								}, 100);
							},
							(err) => {
								alert(err);
							}
						);
					}

					requestAnimationFrame(spin);

				} ).catch( function ( error ) {
					console.error( 'Unable to access the camera/webcam.', error );
				} );
			}


			// var vidTexture = new THREE.VideoTexture(video);
			// var vidTexture = new THREE.CanvasTexture(canvas);
			// vidTexture.minFilter = vidTexture.magFilter = THREE.NearestFilter;
			// vidTexture.minFilter = THREE.LinearFilter; // text in map that we want to ready..
			// vidTexture.magFilter = THREE.LinearFilter;

			// _mapVideo = vidTexture;



			init();
			animate();

			vidTexture = new THREE.CanvasTexture(renderer.domElement);
			setInterval(() => {
				vidTexture.needsUpdate = true;
			}, 150);

			// return;


			// var video = document.createElement('video');

			// video.width	= 512;
			// video.height = 512;

			// video.loop = true;
			// video.autoplay = true; // todo: double-check this is correct. If not applied video can be extreemely slow in Chrome(!) (bug??)
			// video.muted = true;

			// video.src = 'mov_bbb.mp4';
			// video.play();

			// _mapVideo = new THREE.VideoTexture(video);


			// init();
			// animate();

		}
	</script>
</body>
</html>
